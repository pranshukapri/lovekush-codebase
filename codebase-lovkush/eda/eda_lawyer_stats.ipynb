{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_name = \"../data_preprocessed_csv/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = os.listdir(dir_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df_from_filename(filename):\n",
    "    df = pd.read_csv(dir_name + filename, index_col=0)\n",
    "    return df\n",
    "\n",
    "\n",
    "def create_list_of_questioners(df):\n",
    "    return df[df.text_type == \"q\"].speaker.unique().tolist()\n",
    "\n",
    "\n",
    "def find_filenames_with_multiples_questioners(filenames):\n",
    "    filenames_multiple_questioners = []\n",
    "    for filename in filenames:\n",
    "        df = create_df_from_filename(filename)\n",
    "        questioners = create_list_of_questioners(df)\n",
    "        if len(questioners) > 1:\n",
    "            print(f\"{filename}\\n{questioners}\\n\")\n",
    "            filenames_multiple_questioners.append(filename)\n",
    "\n",
    "    return filenames_multiple_questioners\n",
    "\n",
    "\n",
    "def create_questioner_stats_from_filename(filename):\n",
    "    df = create_df_from_filename(filename)\n",
    "    df[\"num_words\"] = df.text.map(lambda x: len(str(x).split()))\n",
    "    df[\"objection\"] = (df.text_type == \"q\") & (df.text_type.shift(-1) == \"side_chat\")\n",
    "    df[\"strike_that\"] = df.text.map(\n",
    "        lambda x: \"scratch that\" in str(x).lower() or \"strike that\" in str(x).lower()\n",
    "    )\n",
    "\n",
    "    df_questioners = (\n",
    "        df[df.text_type == \"q\"]\n",
    "        .groupby(\"speaker\")\n",
    "        .agg({\"speaker\": \"count\", \"num_words\": \"mean\", \"objection\": \"sum\", 'strike_that': \"sum\"})\n",
    "        .rename(\n",
    "            columns={\n",
    "                \"speaker\": \"num_questions\",\n",
    "                \"num_words\": \"av_num_words\",\n",
    "                \"objection\": \"objection_ratio\",\n",
    "                \"strike_that\": 'strike_ratio'\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "\n",
    "    df_questioners[\"objection_ratio\"] = (\n",
    "        df_questioners.objection_ratio / df_questioners.num_questions\n",
    "    )\n",
    "    df_questioners[\"strike_ratio\"] = (\n",
    "        df_questioners.strike_ratio / df_questioners.num_questions\n",
    "    )\n",
    "    df_questioners[\"filename\"] = filename\n",
    "\n",
    "    return df, df_questioners\n",
    "\n",
    "\n",
    "def print_questions_with_objections(filename):\n",
    "    df, _ = create_questioner_stats_from_filename(filename)\n",
    "    # select indices of objectionable questions *and* the objection itself\n",
    "    indices = (df.objection) | (df.objection.shift(1))\n",
    "    for index, row in df[indices].iterrows():\n",
    "        print(f\"{row.speaker:15}: {row.text}\")\n",
    "\n",
    "\n",
    "def print_questions_striked(filename):\n",
    "    df, _ = create_questioner_stats_from_filename(filename)\n",
    "    indices = (df.strike_that)\n",
    "    for index, row in df[indices].iterrows():\n",
    "        print(f\"{row.speaker:15}: {row.text}\")\n",
    "        \n",
    "\n",
    "def create_questioner_stats_from_filenames(filenames):\n",
    "    # initialise dataframe with first file\n",
    "    _, df_corpus = create_questioner_stats_from_filename(filenames[0])\n",
    "\n",
    "    for filename in tqdm(filenames[1:]):\n",
    "        _, df_file = create_questioner_stats_from_filename(filename)\n",
    "        df_corpus = df_corpus.append(df_file)\n",
    "    return df_corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## investigate questioners stats across all files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b56fcaeb5c944ddf9cce74f6f8add6de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/141 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_questioners_corpus = create_questioner_stats_from_filenames(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_questioners_corpus.to_csv('lawyers_stats.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### highest average number of words per question.\n",
    "removed people with fewer than 20 questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_questioners_corpus.loc[\n",
    "    df_questioners_corpus.num_questions > 20,\n",
    "    [\"num_questions\", \"av_num_words\", \"filename\"],\n",
    "].sort_values(by=\"av_num_words\", axis=0, ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lowest average number of words per question.\n",
    "removed people with fewer than 20 questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_questioners_corpus.loc[\n",
    "    df_questioners_corpus.num_questions > 20,\n",
    "    [\"num_questions\", \"av_num_words\", \"filename\"],\n",
    "].sort_values(by=\"av_num_words\", axis=0, ascending=True).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### highest objection ratio\n",
    "removed entries with fewer than 20 questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_questioners_corpus.loc[\n",
    "    df_questioners_corpus.num_questions > 20,\n",
    "    [\"num_questions\", \"objection_ratio\", \"filename\"],\n",
    "].sort_values(by=\"objection_ratio\", axis=0, ascending=False).head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'Morton,_David_-_Vol._1_-_Video.csv'\n",
    "# filename = 'Lee_v_Hobart_-_8-26-19_-_Galatsis_-_FINAL.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_questions_with_objections(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### highest strike ratio\n",
    "removed entries with fewer than 20 questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_questioners_corpus.loc[\n",
    "    (df_questioners_corpus.num_questions > 20)\n",
    "    & ~(df_questioners_corpus.filename.isin([\"8-20-19-B-TS.csv\", \"8-20-19-TS.csv\", \"82819_Sicilia_Saimesier(1).csv\"])),\n",
    "    [\"num_questions\", \"strike_ratio\", \"filename\"],\n",
    "].sort_values(by=\"strike_ratio\", axis=0, ascending=False).head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'SPorterfield.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_questions_striked(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## investigate questioner stats in an individual file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = 'Morton,_David_-_Vol._1_-_Video.csv'\n",
    "filename = 'Lee_v_Hobart_-_8-26-19_-_Galatsis_-_FINAL.csv'\n",
    "df, df_questioners = create_questioner_stats_from_filename(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_questioners.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_questions_with_objections(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## files with more than one questioner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames_mult_questioners = find_filenames_with_multiples_questioners(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
